{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import datetime as dt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from dateutil import parser\n",
    "from sklearn.model_selection import train_test_split# Split the data into training and testing sets\n",
    "import joblib, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Processing:\n",
    "    def __init__(self,data_path,label_path):\n",
    "        self.data = data_path\n",
    "        self.label= label_path\n",
    "    def process(data_path,label_path):\n",
    "        scores_df = pd.read_csv(label_path)\n",
    "\n",
    "        #hit scores\n",
    "        hit_df = scores_df[[\"subject\",\"date\",\"crossing number\",\"run\",\"limb\",\"avg_human_hit\"]]\n",
    "\n",
    "        #miss\n",
    "        miss_df = scores_df[[\"subject\",\"date\",\"crossing number\",\"run\",\"limb\",\"avg_human_miss\"]]\n",
    "\n",
    "        #steps\n",
    "        step_df = scores_df[[\"subject\",\"date\",\"crossing number\",\"run\",\"limb\",\"avg_human_steps\"]]\n",
    "\n",
    "        #score extraction\n",
    "        dom_f_hit = hit_df.loc[hit_df[\"limb\"]==\"Dominant Front\"]\n",
    "        dom_f_miss = miss_df.loc[miss_df[\"limb\"]==\"Dominant Front\"]\n",
    "        dom_f_step = step_df.loc[step_df[\"limb\"]==\"Dominant Front\"]\n",
    "\n",
    "        ndom_f_hit = hit_df.loc[hit_df[\"limb\"]==\"Nondominant Front\"]\n",
    "        ndom_f_miss = miss_df.loc[miss_df[\"limb\"]==\"Nondominant Front\"]\n",
    "        ndom_f_step = step_df.loc[step_df[\"limb\"]==\"Nondominant Front\"]\n",
    "\n",
    "        dom_b_hit = hit_df.loc[hit_df[\"limb\"]==\"Dominant Back\"]\n",
    "        dom_b_miss = miss_df.loc[miss_df[\"limb\"]==\"Dominant Back\"]\n",
    "        dom_b_step = step_df.loc[step_df[\"limb\"]==\"Dominant Back\"]\n",
    "\n",
    "        ndom_b_hit = hit_df.loc[hit_df[\"limb\"]==\"Nondominant Back\"]\n",
    "        ndom_b_miss = miss_df.loc[miss_df[\"limb\"]==\"Nondominant Back\"]\n",
    "        ndom_b_step = step_df.loc[step_df[\"limb\"]==\"Nondominant Back\"]\n",
    "        dom_f_hit_x = []\n",
    "        dom_f_miss_x = []\n",
    "        dom_f_step_x =[]\n",
    "\n",
    "        ndom_f_hit_x = []\n",
    "        ndom_f_miss_x = []\n",
    "        ndom_f_step_x = []\n",
    "\n",
    "        dom_b_hit_x = []\n",
    "        dom_b_miss_x = []\n",
    "        dom_b_step_x = []\n",
    "\n",
    "        ndom_b_hit_x = []\n",
    "        ndom_b_miss_x = []\n",
    "        ndom_b_step_x = []\n",
    "\n",
    "        #sets of labels\n",
    "        dom_f_hit_y = []\n",
    "        dom_f_miss_y = []\n",
    "        dom_f_step_y =[]\n",
    "\n",
    "        ndom_f_hit_y = []\n",
    "        ndom_f_miss_y = []\n",
    "        ndom_f_step_y = []\n",
    "\n",
    "        dom_b_hit_y = []\n",
    "        dom_b_miss_y = []\n",
    "        dom_b_step_y = []\n",
    "\n",
    "        ndom_b_hit_y = []\n",
    "        ndom_b_miss_y = []\n",
    "        ndom_b_step_y = []\n",
    "\n",
    "        lengths = []\n",
    "        rat_folder = glob.glob(data_path)\n",
    "        \n",
    "        for file in rat_folder:\n",
    "            #rat tracking file\n",
    "            #name of the rung file\n",
    "            rung_name_list = file.split(\"/\")[-1].split(\"_\")[0:8]+[\"LadderWalkMar12shuffle1\",\"450000.h5\"]\n",
    "            rung_file = '_'.join(rung_name_list)\n",
    "            #open the file\n",
    "            rat_df = pd.read_hdf(file)[\"DLC_resnet50_LadderWalkFeb13shuffle1_450000\"]\n",
    "            #properties of the file\n",
    "            subject = file.split(\"/\")[0]\n",
    "            date_raw = rung_name_list[1]\n",
    "            date = parser.parse(date_raw).date().strftime(\"%Y-%m-%d\")\n",
    "            run = rung_name_list[2]\n",
    "            crossing = [int(s) for s in rung_name_list[3] if s.isdigit()][0]\n",
    "            #\n",
    "            dom_f_hit_score = dom_f_hit[(dom_f_hit[\"subject\"]==subject) & (dom_f_hit[\"date\"]==date) & (dom_f_hit[\"run\"]==run)].reset_index()\n",
    "            dom_f_miss_score = dom_f_miss[(dom_f_miss[\"subject\"]==subject) & (dom_f_miss[\"date\"]==date) & (dom_f_miss[\"run\"]==run)].reset_index()\n",
    "            dom_f_step_score = dom_f_step[(dom_f_step[\"subject\"]==subject) & (dom_f_step[\"date\"]==date) & (dom_f_step[\"run\"]==run)].reset_index()\n",
    "\n",
    "            ndom_f_hit_score = ndom_f_hit[(ndom_f_hit[\"subject\"]==subject) & (ndom_f_hit[\"date\"]==date) & (ndom_f_hit[\"run\"]==run)].reset_index()\n",
    "            ndom_f_miss_score = ndom_f_miss[(ndom_f_miss[\"subject\"]==subject) & (ndom_f_miss[\"date\"]==date) & (ndom_f_miss[\"run\"]==run)].reset_index()\n",
    "            ndom_f_step_score = ndom_f_step[(ndom_f_step[\"subject\"]==subject) & (ndom_f_step[\"date\"]==date) & (ndom_f_step[\"run\"]==run)].reset_index()\n",
    "\n",
    "            dom_b_hit_score = dom_b_hit[(dom_b_hit[\"subject\"]==subject) & (dom_b_hit[\"date\"]==date) & (dom_b_hit[\"run\"]==run)].reset_index()\n",
    "            dom_b_miss_score = dom_b_miss[(dom_b_miss[\"subject\"]==subject) & (dom_b_miss[\"date\"]==date) & (dom_b_miss[\"run\"]==run)].reset_index()\n",
    "            dom_b_step_score = dom_b_step[(dom_b_step[\"subject\"]==subject) & (dom_b_step[\"date\"]==date) & (dom_b_step[\"run\"]==run)].reset_index()\n",
    "\n",
    "            ndom_b_hit_score = ndom_b_hit[(ndom_b_hit[\"subject\"]==subject) & (ndom_b_hit[\"date\"]==date) & (ndom_b_hit[\"run\"]==run)].reset_index()\n",
    "            ndom_b_miss_score = ndom_b_miss[(ndom_b_miss[\"subject\"]==subject) & (ndom_b_miss[\"date\"]==date) & (ndom_b_miss[\"run\"]==run)].reset_index()\n",
    "            ndom_b_step_score = ndom_b_step[(ndom_b_step[\"subject\"]==subject) & (ndom_b_step[\"date\"]==date) & (ndom_b_step[\"run\"]==run)].reset_index()\n",
    "\n",
    "            #join the rat and rung dataframes\n",
    "            df = rat_df\n",
    "            df_cols = df.columns.tolist()\n",
    "            df_temp = df\n",
    "\n",
    "            #remove where median likelihood is low\n",
    "            #df_low_like = df.columns[-df_temp[df_temp.columns.get_level_values(0).unique()].median().ge(0.2)].get_level_values(0).tolist()\n",
    "            #df_cols_up = [x for x in df_cols if x not in df_low_like ]\n",
    "\n",
    "            #df = rat_df[df_cols_up]\n",
    "            if df.shape[1] == 0:\n",
    "                continue\n",
    "            #if len(dom_f_low_like) >0:\n",
    "                #print(dom_f_low_like)\n",
    "            df = df.drop('likelihood', axis=1, level=1)\n",
    "\n",
    "            #scale data\n",
    "            ####Uses the values function of pandas - converts any dataframe to an array\n",
    "            data_for_scaling = df.values\n",
    "            #### the scaling object\n",
    "            scaler = MinMaxScaler()\n",
    "            #We will use fit_transform here - we want to actually scale this data, not use the scaler on a different dataset\n",
    "            scaled_data = scaler.fit_transform(data_for_scaling)\n",
    "\n",
    "            if len(scaled_data) < 356:\n",
    "                newlength = (356-len(scaled_data))\n",
    "                zero = np.zeros((newlength,6))\n",
    "                scaled_temp = pd.DataFrame(scaled_data).append(pd.DataFrame(zero),ignore_index=True)\n",
    "                scaled_temp = scaled_temp.fillna(0)\n",
    "                scaled_data2 = scaled_temp.values\n",
    "            else:\n",
    "                scaled_data2 = scaled_data\n",
    "\n",
    "            video_data = scaled_data2.flatten()\n",
    "            #lengths.append([len(video_data)])\n",
    "            if len(dom_f_hit_score) !=0:\n",
    "                dom_f_hit_y.append(dom_f_hit_score[\"avg_human_hit\"][0])\n",
    "                dom_f_hit_x.append(video_data)\n",
    "            else:\n",
    "                print(\"Dom Front Hit\"+\"Missing scores: \"+subject + \" \" + date + \" \" + run)\n",
    "            if len(dom_f_miss_score) != 0:\n",
    "                dom_f_miss_y.append(dom_f_miss_score[\"avg_human_miss\"][0])\n",
    "                dom_f_miss_x.append(video_data)\n",
    "            else:\n",
    "                print(\"Dom Front Miss\"+\"Missing scores: \"+subject + \" \" + date + \" \" + run)\n",
    "            if len(dom_f_step_score) != 0:\n",
    "                dom_f_step_y.append(dom_f_step_score[\"avg_human_steps\"][0])\n",
    "                dom_f_step_x.append(video_data)\n",
    "            else:\n",
    "                print(\"Dom Front Step\"+\"Missing scores: \"+subject + \" \" + date + \" \" + run)\n",
    "            if len(ndom_f_hit_score) != 0:\n",
    "                ndom_f_hit_y.append(ndom_f_hit_score[\"avg_human_hit\"][0])\n",
    "                ndom_f_hit_x.append(video_data)\n",
    "            else:\n",
    "                print(\"Nondom Front Hit\"+\"Missing scores: \"+subject + \" \" + date + \" \" + run)\n",
    "            if len(ndom_f_miss_score) != 0:\n",
    "                ndom_f_miss_y.append(ndom_f_miss_score[\"avg_human_miss\"][0])\n",
    "                ndom_f_miss_x.append(video_data)\n",
    "            else:\n",
    "                print(\"Nondom Front Miss\"+\"Missing scores: \"+subject + \" \" + date + \" \" + run)\n",
    "            if len(ndom_f_step_score) != 0:\n",
    "                ndom_f_step_y.append(ndom_f_step_score[\"avg_human_steps\"][0])\n",
    "                ndom_f_step_x.append(video_data)\n",
    "            else:\n",
    "                print(\"Nondom Front Step\"+\"Missing scores: \"+subject + \" \" + date + \" \" + run)\n",
    "            if len(dom_b_hit_score) != 0:\n",
    "                dom_b_hit_y.append(dom_b_hit_score[\"avg_human_hit\"][0])\n",
    "                dom_b_hit_x.append(video_data)\n",
    "            else:\n",
    "                print(\"Dom Back Hit\"+\"Missing scores: \"+subject + \" \" + date + \" \" + run)\n",
    "            if len(dom_b_miss_score) != 0:\n",
    "                dom_b_miss_y.append(dom_b_miss_score[\"avg_human_miss\"][0])\n",
    "                dom_b_miss_x.append(video_data)\n",
    "            else:\n",
    "                print(\"Dom Back Miss\"+\"Missing scores: \"+subject + \" \" + date + \" \" + run)\n",
    "            if len(dom_b_step_score) != 0:\n",
    "                dom_b_step_y.append(dom_b_step_score[\"avg_human_steps\"][0])\n",
    "                dom_b_step_x.append(video_data)\n",
    "            else:\n",
    "                print(\"Dom Back Step\"+\"Missing scores: \"+subject + \" \" + date + \" \" + run)\n",
    "            if len(ndom_b_hit_score) != 0:\n",
    "                ndom_b_hit_y.append(ndom_b_hit_score[\"avg_human_hit\"][0])\n",
    "                ndom_b_hit_x.append(video_data)\n",
    "            else:\n",
    "                print(\"Nondom Back Hit\"+\"Missing scores: \"+subject + \" \" + date + \" \" + run)\n",
    "            if len(ndom_b_miss_score) != 0:\n",
    "                ndom_b_miss_y.append(ndom_b_miss_score[\"avg_human_miss\"][0])\n",
    "                ndom_b_miss_x.append(video_data)\n",
    "            else:\n",
    "                print(\"Nondom Back Miss\"+\"Missing scores: \"+subject + \" \" + date + \" \" + run)\n",
    "            if len(ndom_b_step_score) != 0:\n",
    "                ndom_b_step_y.append(ndom_b_step_score[\"avg_human_steps\"][0])\n",
    "                ndom_b_step_x.append(video_data)\n",
    "            else:\n",
    "                print(\"Nondom Back Step\"+\"Missing scores: \"+subject + \" \" + date + \" \" + run)\n",
    "                continue\n",
    "        return [dom_f_hit_x, dom_f_miss_x, dom_f_step_x, ndom_f_hit_x, ndom_f_miss_x, ndom_f_step_x,\n",
    "    dom_b_hit_x, dom_b_miss_x, dom_b_step_x, ndom_b_hit_x, ndom_b_miss_x, ndom_b_step_x],[dom_f_hit_y, dom_f_miss_y, dom_f_step_y, ndom_f_hit_y, ndom_f_miss_y, ndom_f_step_y, dom_b_hit_y,\n",
    "    dom_b_miss_y, dom_b_step_y, ndom_b_hit_y, ndom_b_miss_y, ndom_b_step_y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scoring:\n",
    "    def __init__(self):\n",
    "        self = self\n",
    "    def forest(X,y,rf_name,data_path,project_name, njobs=None):\n",
    "        data = np.array(X)\n",
    "        labels = np.array(y)\n",
    "        train_features, test_features, train_labels, test_labels = train_test_split(data, labels, test_size = 0.25, random_state = 42)\n",
    "        # Instantiate model with n decision trees\n",
    "        rf = RandomForestRegressor(n_estimators = 1000, random_state = 42,n_jobs=njobs)# Train the model on training data\n",
    "        rf.fit(train_features, train_labels)\n",
    "        # Use the forest's predict method on the test data\n",
    "        predictions = rf.predict(test_features)# Calculate the absolute errors\n",
    "        errors = abs(predictions - test_labels)# Print out the mean absolute error (mae)\n",
    "        # Calculate mean absolute percentage error (MAPE)\n",
    "        mape = 100 * (errors / test_labels)# Calculate and display accuracy\n",
    "        accuracy = 100 - np.mean(mape)\n",
    "        joblib.dump(rf, rf_name+\".joblib\", compress=0) \n",
    "        print(f\"Uncompressed Random Forest: {np.round(os.path.getsize(rf_name+'.joblib') / 1024 / 1024, 2) } MB\")\n",
    "        \n",
    "        rat_folder = glob.glob(data_path)\n",
    "        df = pd.read_hdf(rat_folder[0])[project_name]\n",
    "        df = df.drop('likelihood', axis=1, level=1)\n",
    "        feats = {} # a dict to hold feature_name: feature_importance\n",
    "        for feature, importance in zip(df.columns, rf.feature_importances_):\n",
    "            feats[feature] = importance #add the name/value pair \n",
    "        importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Gini-importance'})\n",
    "        return accuracy, importances.sort_values(by=\"Gini-importance\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nondom Front HitMissing scores: MC70 2019-04-11 R5\n",
      "Nondom Front MissMissing scores: MC70 2019-04-11 R5\n",
      "Nondom Front StepMissing scores: MC70 2019-04-11 R5\n",
      "Dom Back HitMissing scores: MC70 2019-04-11 R5\n",
      "Dom Back MissMissing scores: MC70 2019-04-11 R5\n",
      "Dom Back StepMissing scores: MC70 2019-04-11 R5\n",
      "Nondom Back HitMissing scores: MC70 2019-04-11 R5\n",
      "Nondom Back MissMissing scores: MC70 2019-04-11 R5\n",
      "Nondom Back StepMissing scores: MC70 2019-04-11 R5\n",
      "Dom Front HitMissing scores: MC70 2019-03-14 L4\n",
      "Dom Front MissMissing scores: MC70 2019-03-14 L4\n",
      "Dom Front StepMissing scores: MC70 2019-03-14 L4\n",
      "Nondom Front HitMissing scores: MC70 2019-03-14 L4\n",
      "Nondom Front MissMissing scores: MC70 2019-03-14 L4\n",
      "Nondom Front StepMissing scores: MC70 2019-03-14 L4\n",
      "Dom Back HitMissing scores: MC70 2019-03-14 L4\n",
      "Dom Back MissMissing scores: MC70 2019-03-14 L4\n",
      "Dom Back StepMissing scores: MC70 2019-03-14 L4\n",
      "Nondom Back HitMissing scores: MC70 2019-03-14 L4\n",
      "Nondom Back MissMissing scores: MC70 2019-03-14 L4\n",
      "Nondom Back StepMissing scores: MC70 2019-03-14 L4\n",
      "Dom Front HitMissing scores: MC70 2019-04-09 L4\n",
      "Dom Front MissMissing scores: MC70 2019-04-09 L4\n",
      "Dom Front StepMissing scores: MC70 2019-04-09 L4\n",
      "Nondom Front HitMissing scores: MC70 2019-04-09 L4\n",
      "Nondom Front MissMissing scores: MC70 2019-04-09 L4\n",
      "Nondom Front StepMissing scores: MC70 2019-04-09 L4\n",
      "Dom Back HitMissing scores: MC70 2019-04-09 L4\n",
      "Dom Back MissMissing scores: MC70 2019-04-09 L4\n",
      "Dom Back StepMissing scores: MC70 2019-04-09 L4\n",
      "Nondom Back HitMissing scores: MC70 2019-04-09 L4\n",
      "Nondom Back MissMissing scores: MC70 2019-04-09 L4\n",
      "Nondom Back StepMissing scores: MC70 2019-04-09 L4\n"
     ]
    }
   ],
   "source": [
    "datas = Processing.process(\"*/dlc_output_resnet50/*.h5\",\"LW_Manual_scores_for_ICC_2020-05-20.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = datas[0]\n",
    "labels_y = datas[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\"dominant_front_hit\", \"dominant_front_miss\", \"dominant_front_step\", \n",
    " \"nondominant_front_hit\", \"nondominant_front_miss\", \"nondominant_front_step\",\n",
    "    \"dominant_back_hit\", \"dominant_back_miss\", \"dominant_back_step\", \n",
    " \"nondominant_back_hit\", \"nondominant_back_miss\", \"nondominant_back_step\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 dominant_front_hit\n",
      "Uncompressed Random Forest: 7.3 MB\n",
      "81.30436218714236                    Gini-importance\n",
      "(left fingers, y)         0.002549\n",
      "(hip, y)                  0.002072\n",
      "(left elbow, y)           0.002050\n",
      "(right ankle, y)          0.001814\n",
      "(left wrist, y)           0.001277\n",
      "1 dominant_front_miss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-be73539821f5>:15: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  mape = 100 * (errors / test_labels)# Calculate and display accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncompressed Random Forest: 6.34 MB\n",
      "-inf                    Gini-importance\n",
      "(right eye, y)            0.002145\n",
      "(left fingers, y)         0.001830\n",
      "(left wrist, y)           0.001325\n",
      "(nose, y)                 0.001162\n",
      "(right wrist, y)          0.000720\n",
      "2 dominant_front_step\n",
      "Uncompressed Random Forest: 6.43 MB\n",
      "86.88746867300493                    Gini-importance\n",
      "(left fingers, y)         0.001107\n",
      "(left ankle, y)           0.000691\n",
      "(right ankle, y)          0.000575\n",
      "(right elbow, y)          0.000561\n",
      "(base of tail, y)         0.000506\n",
      "3 nondominant_front_hit\n",
      "Uncompressed Random Forest: 7.32 MB\n",
      "85.36458768527504                  Gini-importance\n",
      "(hip, y)                0.000527\n",
      "(left wrist, y)         0.000477\n",
      "(left eye, y)           0.000364\n",
      "(right toes, y)         0.000348\n",
      "(nose, y)               0.000339\n",
      "4 nondominant_front_miss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-be73539821f5>:15: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  mape = 100 * (errors / test_labels)# Calculate and display accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncompressed Random Forest: 5.35 MB\n",
      "-inf                   Gini-importance\n",
      "(left eye, y)            0.006986\n",
      "(left toes, y)           0.001851\n",
      "(right ankle, y)         0.001585\n",
      "(nose, y)                0.001339\n",
      "(right eye, y)           0.001283\n",
      "5 nondominant_front_step\n",
      "Uncompressed Random Forest: 6.86 MB\n",
      "85.5936721786659                   Gini-importance\n",
      "(left wrist, y)          0.000394\n",
      "(left elbow, y)          0.000281\n",
      "(left eye, y)            0.000260\n",
      "(left toes, y)           0.000252\n",
      "(right ankle, y)         0.000239\n",
      "6 dominant_back_hit\n",
      "Uncompressed Random Forest: 6.2 MB\n",
      "86.5488967689398                    Gini-importance\n",
      "(hip, y)                  0.005808\n",
      "(left elbow, y)           0.002031\n",
      "(left fingers, y)         0.001823\n",
      "(right wrist, y)          0.001373\n",
      "(right ankle, y)          0.001327\n",
      "7 dominant_back_miss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-be73539821f5>:15: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  mape = 100 * (errors / test_labels)# Calculate and display accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncompressed Random Forest: 2.58 MB\n",
      "-inf                    Gini-importance\n",
      "(left fingers, y)         0.001661\n",
      "(right wrist, x)          0.000729\n",
      "(left ankle, y)           0.000433\n",
      "(right ankle, y)          0.000386\n",
      "(left toes, y)            0.000373\n",
      "8 dominant_back_step\n",
      "Uncompressed Random Forest: 6.12 MB\n",
      "89.65668524243952                    Gini-importance\n",
      "(left elbow, y)           0.003228\n",
      "(right ankle, y)          0.003166\n",
      "(left toes, y)            0.000922\n",
      "(right eye, y)            0.000845\n",
      "(left fingers, y)         0.000711\n",
      "9 nondominant_back_hit\n",
      "Uncompressed Random Forest: 5.73 MB\n",
      "87.8924065446048                    Gini-importance\n",
      "(right ankle, y)          0.002038\n",
      "(left fingers, y)         0.000978\n",
      "(nose, y)                 0.000926\n",
      "(hip, y)                  0.000880\n",
      "(right toes, y)           0.000760\n",
      "10 nondominant_back_miss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-be73539821f5>:15: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  mape = 100 * (errors / test_labels)# Calculate and display accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncompressed Random Forest: 2.16 MB\n",
      "-inf                   Gini-importance\n",
      "(left toes, y)           0.000480\n",
      "(left ankle, y)          0.000438\n",
      "(right elbow, y)         0.000382\n",
      "(nose, y)                0.000377\n",
      "(left wrist, y)          0.000323\n",
      "11 nondominant_back_step\n",
      "Uncompressed Random Forest: 5.83 MB\n",
      "89.31786910697188                   Gini-importance\n",
      "(left toes, y)           0.003919\n",
      "(left elbow, y)          0.001645\n",
      "(hip, y)                 0.000883\n",
      "(left ankle, y)          0.000726\n",
      "(right ankle, y)         0.000674\n"
     ]
    }
   ],
   "source": [
    "for i,k in enumerate(keys):\n",
    "    print(i,k)\n",
    "    acc, feat = Scoring.forest(data_x[i],labels_y[i],k,\"*/dlc_output_resnet50/*.h5\",\"DLC_resnet50_LadderWalkFeb13shuffle1_450000\",njobs=6)\n",
    "    print(acc,feat.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
