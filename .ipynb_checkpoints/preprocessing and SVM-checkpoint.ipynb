{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import datetime as dt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVR, SVC\n",
    "from dateutil import parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isabelle/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1596: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/home/isabelle/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    }
   ],
   "source": [
    "scores_df = pd.read_csv(\"LW_Manual_scores_for_ICC_2020-05-20.csv\")\n",
    "\n",
    "#hit scores\n",
    "hit_df = scores_df[[\"subject\",\"date\",\"crossing number\",\"run\",\"limb\",\"human_hit_1\",\"human_hit_2\",\"human_hit_3\"]]\n",
    "#take the mode. If no mode, take the mean and round up\n",
    "hit_df.loc[:,\"human_hit\"]=hit_df[[\"human_hit_1\",\"human_hit_2\",\"human_hit_3\"]].mode(axis=1).mean(axis=1).round(0)\n",
    "\n",
    "#score extraction\n",
    "dom_f_hit = hit_df.loc[hit_df[\"limb\"]==\"Dominant Front\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rat_folder = glob.glob(\"*/dlc_output_resnet50/*.h5\")\n",
    "rung_folder = glob.glob(\"*/dlc_rung_r50/*.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC702019-03-14L4not found\n",
      "MC702019-04-09L4not found\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "lengths = []\n",
    "for file in rat_folder:\n",
    "    #rat tracking file\n",
    "    #name of the rung file\n",
    "    rung_name_list = file.split(\"/\")[-1].split(\"_\")[0:8]+[\"LadderWalkMar12shuffle1\",\"450000.h5\"]\n",
    "    rung_file = '_'.join(rung_name_list)\n",
    "    #open the file\n",
    "    rat_df = pd.read_hdf(file)[\"DLC_resnet50_LadderWalkFeb13shuffle1_450000\"]\n",
    "    #properties of the file\n",
    "    subject = file.split(\"/\")[0]\n",
    "    date_raw = rung_name_list[1]\n",
    "    date = parser.parse(date_raw).date().strftime(\"%Y-%m-%d\")\n",
    "    run = rung_name_list[2]\n",
    "    crossing = [int(s) for s in rung_name_list[3] if s.isdigit()][0]\n",
    "    #\n",
    "    dom_f_hit_score = dom_f_hit[(dom_f_hit[\"subject\"]==subject) & (dom_f_hit[\"date\"]==date) & (dom_f_hit[\"run\"]==run)].reset_index()\n",
    "    if len(dom_f_hit_score) == 0:\n",
    "        print(subject + date + run + \"not found\")\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    #open corresponding rung file\n",
    "    #rung_df = pd.read_hdf(subject+\"/dlc_rung_r50/\"+rung_file)[\"DLC_resnet50_LadderWalkMar12shuffle1_450000\"]\n",
    "\n",
    "    #join the rat and rung dataframes\n",
    "    #merge_df = rat_df.join(rung_df)\n",
    "    dom_f_cols = ['right elbow','right wrist','right fingers']\n",
    "\n",
    "    #new dataframe with columns removed\n",
    "    #dom_f = merge_df[dom_f_cols_up]\n",
    "    dom_f_temp = rat_df[dom_f_cols]\n",
    "    \n",
    "    #remove where median likelihood is low\n",
    "    dom_f_low_like = dom_f_temp.columns[-dom_f_temp[dom_f_temp.columns.get_level_values(0).unique()].median().ge(0.2)].get_level_values(0).tolist()\n",
    "    dom_f_cols_up = [x for x in dom_f_cols if x not in dom_f_low_like ]\n",
    "\n",
    "    dom_f = rat_df[dom_f_cols_up]\n",
    "    if dom_f.shape[1] == 0:\n",
    "        continue\n",
    "    y.append(dom_f_hit_score[\"human_hit\"][0])\n",
    "    #if len(dom_f_low_like) >0:\n",
    "        #print(dom_f_low_like)\n",
    "    dom_f = dom_f.drop('likelihood', axis=1, level=1)\n",
    "\n",
    "    #scale data\n",
    "    ####Uses the values function of pandas - converts any dataframe to an array\n",
    "    data_for_scaling = dom_f.values\n",
    "    #### the scaling object\n",
    "    scaler = MinMaxScaler()\n",
    "    #We will use fit_transform here - we want to actually scale this data, not use the scaler on a different dataset\n",
    "    scaled_data = scaler.fit_transform(data_for_scaling)\n",
    "    #PCA\n",
    "    #data_reducer = PCA(n_components=5)\n",
    "    #pca_data = data_reducer.fit_transform(scaled_data)\n",
    "    ''' This loop gives us the top feature of each component using the argmax function '''\n",
    "    #top_features = [np.abs(data_reducer.components_[i]).argmax() for i in range(data_reducer.components_.shape[0])]\n",
    "\n",
    "\n",
    "    ''' Now, we go back to our original feature names (columns of our dataset), and get the names of the 4 key features '''\n",
    "    #top_feature_names = [list(dom_f.columns)[top_features[i]] for i in range(data_reducer.components_.shape[0])]\n",
    "\n",
    "    ''' printing the names '''\n",
    "    #for n,name in enumerate(top_feature_names):\n",
    "        #print(\"#\" + str(n) + \": \" + str(name))\n",
    "\n",
    "    #print(data_reducer.components_)\n",
    "    #print(data_reducer.explained_variance_ratio_)\n",
    "    \n",
    "    \n",
    "    if len(scaled_data) < 356:\n",
    "        newlength = (356-len(scaled_data))\n",
    "        zero = np.zeros((newlength,6))\n",
    "        scaled_temp = pd.DataFrame(scaled_data).append(pd.DataFrame(zero),ignore_index=True)\n",
    "        scaled_temp = scaled_temp.fillna(0)\n",
    "        scaled_data2 = scaled_temp.values\n",
    "    else:\n",
    "        scaled_data2 = scaled_data\n",
    "    \n",
    "    video_data = scaled_data2.flatten()\n",
    "    lengths.append([len(video_data)])\n",
    "    X.append(video_data)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2136])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(230, 230)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X),len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = SVR(kernel=\"rbf\")\n",
    "regressor.fit(X,y)\n",
    "y_pred = regressor.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0., -1.,\n",
       "        0.,  0.,  0., -1., -1.,  0.,  0., -1.,  0.,  1.,  0.,  0.,  0.,\n",
       "        0., -1.,  0.,  0.,  1.,  0.,  0.,  0., -1.,  1.,  1., -1.,  0.,\n",
       "       -1.,  0.,  0.,  0.,  0., -1.,  0., -1.,  0.,  1.,  0.,  1.,  0.,\n",
       "        0., -1.,  0.,  0.,  0.,  1.,  1.,  0.,  0., -1., -1., -1.,  0.,\n",
       "        1., -1.,  0.,  0.,  1.,  0., -1.,  0.,  0., -2.,  0.,  0., -1.,\n",
       "        1.,  0.,  0.,  0., -1.,  0.,  1., -1.,  1., -1.,  0., -1.,  1.,\n",
       "        1., -1.,  0.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,  1.,  0., -1.,\n",
       "       -1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  0., -1.,  0.,  0.,\n",
       "       -1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0., -1.,  1.,\n",
       "        1.,  1.,  0.,  0., -1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,\n",
       "        0.,  0.,  0.,  0.,  1.,  0.,  1.,  1.,  0.,  0.,  1.,  0.,  0.,\n",
       "        0., -1., -1., -1.,  0.,  0., -1.,  1.,  1.,  0.,  1.,  0.,  0.,\n",
       "        0., -1.,  0.,  0., -1., -1.,  0., -1., -1.,  1.,  0.,  0.,  0.,\n",
       "       -2.,  0., -1.,  0., -1.,  0.,  0.,  0.,  0.,  0., -1.,  0., -2.,\n",
       "       -3., -2.,  0.,  0., -1.,  1., -2.,  0., -2.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y-y_pred.round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5260869565217391"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(y,y_pred.round(0),squared=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = SVC(kernel=\"rbf\")\n",
    "regressor.fit(X,y)\n",
    "y_pred = regressor.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "       -1.,  0.,  0.,  0.,  1.,  0.,  0., -1.,  0.,  0.,  0.,  0., -1.,\n",
       "        0.,  1.,  0., -1.,  0.,  0.,  1., -1.,  0.,  1.,  0.,  0.,  0.,\n",
       "        0., -1.,  0.,  0.,  1.,  0.,  0.,  0., -1.,  1.,  1., -2.,  0.,\n",
       "       -2.,  0.,  0.,  0.,  0., -1.,  0., -1.,  0.,  1.,  0.,  1.,  0.,\n",
       "        0., -1.,  0.,  0.,  0.,  1.,  1.,  0.,  0., -1., -1., -1.,  0.,\n",
       "        1., -1.,  0.,  1.,  1.,  0., -1.,  0.,  0., -2.,  0.,  0., -1.,\n",
       "        1.,  0.,  0.,  0., -1.,  0.,  1., -1.,  1., -2.,  0., -1.,  1.,\n",
       "        1., -1.,  0.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,  1.,  1., -1.,\n",
       "       -1.,  0., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  0., -1.,  0.,  0.,\n",
       "       -1.,  0.,  0.,  1.,  0.,  0.,  0., -1.,  1.,  1.,  0., -1.,  1.,\n",
       "        1.,  1.,  0.,  0., -1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  1.,  1.,  0.,  0., -1.,  0.,  0.,  0.,  1.,\n",
       "        0.,  1.,  0.,  0.,  1.,  0.,  1.,  1.,  0., -1.,  1.,  0.,  0.,\n",
       "        0., -1., -2.,  0.,  0.,  0., -1.,  1.,  1.,  0.,  1.,  0.,  0.,\n",
       "        0., -1., -1.,  0., -1., -2.,  0., -1., -1.,  1.,  0.,  0.,  0.,\n",
       "       -2.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -2.,  0., -2.,\n",
       "       -4., -4.,  0.,  0.,  0.,  1., -2.,  0., -3.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y-y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7478260869565218"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y,y_pred.round(0),squared=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.0, 2.0, 3.0, 4.0, 5.0, 6.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
